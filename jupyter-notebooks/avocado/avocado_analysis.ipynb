{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
      "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
      "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
      "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
      "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
      "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
      "\n",
      "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
      "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
      "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
      "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
      "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
      "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
      "\n",
      "   year  region  \n",
      "0  2015  Albany  \n",
      "1  2015  Albany  \n",
      "2  2015  Albany  \n",
      "3  2015  Albany  \n",
      "4  2015  Albany  \n",
      "(18249, 14)\n",
      "------------------------------------------\n",
      "Check null data: \n",
      "AveragePrice    0\n",
      "Total Volume    0\n",
      "4046            0\n",
      "4225            0\n",
      "4770            0\n",
      "Total Bags      0\n",
      "Small Bags      0\n",
      "Large Bags      0\n",
      "XLarge Bags     0\n",
      "type            0\n",
      "year            0\n",
      "region          0\n",
      "dtype: int64\n",
      "\n",
      "Skewness of each numeric column before the removal of outliers: \n",
      "AveragePrice    0.577132\n",
      "Total Volume    3.608709\n",
      "4046            4.423296\n",
      "4225            4.127037\n",
      "4770            6.259901\n",
      "Total Bags      4.497227\n",
      "Small Bags      4.284061\n",
      "Large Bags      7.916074\n",
      "XLarge Bags     6.952878\n",
      "year            0.215342\n",
      "dtype: float64\n",
      "\n",
      "Number of outliers in each numeric column: \n",
      "         Column  No. of outliers\n",
      "0  AveragePrice              193\n",
      "1  Total Volume             2189\n",
      "2          4046             2451\n",
      "3          4225             2551\n",
      "4          4770             2957\n",
      "5    Total Bags             2333\n",
      "6    Small Bags             2187\n",
      "7    Large Bags             2630\n",
      "8   XLarge Bags             3981\n",
      "9          year                0\n",
      "\n",
      "Skewness of each numeric column after the removal of outliers: \n",
      "AveragePrice    0.176548\n",
      "Total Volume    1.973988\n",
      "4046            3.225362\n",
      "4225            3.320334\n",
      "4770            3.882299\n",
      "Total Bags      1.909498\n",
      "Small Bags      2.163002\n",
      "Large Bags      2.640595\n",
      "XLarge Bags     6.272967\n",
      "year            0.288178\n",
      "dtype: float64\n",
      "------------------------------------------\n",
      "\n",
      "Skewness of each numeric column after the Yeo-Johnson transformation: \n",
      "AveragePrice   -0.008166\n",
      "Total Volume    0.017440\n",
      "4046           -0.027678\n",
      "4225           -0.042969\n",
      "4770            0.296849\n",
      "Total Bags     -0.044245\n",
      "Small Bags     -0.058699\n",
      "Large Bags     -0.124781\n",
      "XLarge Bags     2.856872\n",
      "year            0.286031\n",
      "dtype: float64\n",
      "\n",
      "Performing Yeo-Johnson Transformation can make the data more closely follow a normal distribution. However the transformation changes the values in the data so untransformed data would be used for analysis.\n",
      "------------------------------------------\n",
      "1)   Find out the average number of Avocados with PLU 4046 sold in each region (20 points)\n",
      "region\n",
      "Albany                  1060.978633\n",
      "Atlanta                10030.893810\n",
      "BaltimoreWashington     2332.970237\n",
      "Boise                  19949.827760\n",
      "Boston                   583.464486\n",
      "BuffaloRochester        1341.158958\n",
      "California             33403.936707\n",
      "Charlotte              12819.138524\n",
      "Chicago                  408.501775\n",
      "CincinnatiDayton        1614.451356\n",
      "Columbus               22111.224351\n",
      "DallasFtWorth           7708.704556\n",
      "Denver                 11462.850301\n",
      "Detroit                10328.872926\n",
      "GrandRapids              848.000594\n",
      "GreatLakes              5112.127899\n",
      "HarrisburgScranton     17527.984345\n",
      "HartfordSpringfield     2909.387963\n",
      "Houston                 9314.130651\n",
      "Indianapolis            3414.733364\n",
      "Jacksonville           32366.642955\n",
      "LasVegas               41487.715813\n",
      "LosAngeles             14096.070828\n",
      "Louisville              1026.654244\n",
      "MiamiFtLauderdale      20481.428508\n",
      "Midsouth                4505.462778\n",
      "Nashville              33995.808425\n",
      "NewOrleansMobile       48063.728204\n",
      "NewYork                 6758.036707\n",
      "Northeast               9274.229613\n",
      "NorthernNewEngland      2651.787082\n",
      "Orlando                53870.028529\n",
      "Philadelphia            8747.682639\n",
      "PhoenixTucson           5430.586647\n",
      "Pittsburgh              9829.302270\n",
      "Plains                  4041.840828\n",
      "Portland               13265.293313\n",
      "RaleighGreensboro      20336.990817\n",
      "RichmondNorfolk        30594.127285\n",
      "Roanoke                19027.173106\n",
      "Sacramento             33601.478929\n",
      "SanDiego                8496.653275\n",
      "SanFrancisco            8336.297069\n",
      "Seattle                34199.138081\n",
      "SouthCarolina          37825.273956\n",
      "SouthCentral           33989.914675\n",
      "Southeast               8929.052036\n",
      "Spokane                12627.879312\n",
      "StLouis                36539.082601\n",
      "Syracuse                 885.066384\n",
      "Tampa                  48756.803009\n",
      "West                   55772.028333\n",
      "WestTexNewMexico        2643.102609\n",
      "Name: 4046, dtype: float64\n",
      "------------------------------------------\n",
      "2)   Find out the top ten regions organized by total volume arranged highest to lowest (20 points)\n",
      "region\n",
      "Philadelphia           39925654.96\n",
      "HartfordSpringfield    33057061.81\n",
      "RichmondNorfolk        29902858.94\n",
      "HarrisburgScranton     29293560.91\n",
      "LasVegas               25261447.38\n",
      "California             25187621.02\n",
      "Sacramento             24564309.51\n",
      "StLouis                24176958.46\n",
      "NorthernNewEngland     22700936.24\n",
      "Seattle                21649793.40\n",
      "Name: Total Volume, dtype: float64\n",
      "------------------------------------------\n",
      "3)   An average millennial has a rent of $2000. In general they spend 40% of their rent on food and 20% of that amount is spent on breakfast. Which region is the best area to live for millennials if the millennial like to have avocado toast breakfast every 1 time out of three (30 points) Assume you are having one avocado in the breakfast.\n",
      "The average price of avocado with in each region:\n",
      "region\n",
      "Albany                 1.573033\n",
      "Atlanta                1.549405\n",
      "BaltimoreWashington    1.724260\n",
      "Boise                  1.328233\n",
      "Boston                 1.722595\n",
      "BuffaloRochester       1.529583\n",
      "California             1.674731\n",
      "Charlotte              1.777333\n",
      "Chicago                1.744201\n",
      "CincinnatiDayton       1.387006\n",
      "Columbus               1.346736\n",
      "DallasFtWorth          1.324734\n",
      "Denver                 1.373976\n",
      "Detroit                1.404202\n",
      "GrandRapids            1.568813\n",
      "GreatLakes             1.544493\n",
      "HarrisburgScranton     1.551690\n",
      "HartfordSpringfield    1.849593\n",
      "Houston                1.270769\n",
      "Indianapolis           1.437196\n",
      "Jacksonville           1.578068\n",
      "LasVegas               1.481057\n",
      "LosAngeles             1.455562\n",
      "Louisville             1.382647\n",
      "MiamiFtLauderdale      1.545635\n",
      "Midsouth               1.617531\n",
      "Nashville              1.279803\n",
      "NewOrleansMobile       1.365224\n",
      "NewYork                2.053593\n",
      "Northeast              1.880194\n",
      "NorthernNewEngland     1.584506\n",
      "Orlando                1.628950\n",
      "Philadelphia           1.699182\n",
      "PhoenixTucson          1.709880\n",
      "Pittsburgh             1.372105\n",
      "Plains                 1.707515\n",
      "Portland               1.509693\n",
      "RaleighGreensboro      1.688317\n",
      "RichmondNorfolk        1.317869\n",
      "Roanoke                1.271229\n",
      "Sacramento             1.771027\n",
      "SanDiego               1.697368\n",
      "SanFrancisco           1.974741\n",
      "Seattle                1.567849\n",
      "SouthCarolina          1.534622\n",
      "SouthCentral           1.333077\n",
      "Southeast              1.639222\n",
      "Spokane                1.388969\n",
      "StLouis                1.439426\n",
      "Syracuse               1.528176\n",
      "Tampa                  1.506637\n",
      "West                   1.747500\n",
      "WestTexNewMexico       1.665466\n",
      "Name: AveragePrice, dtype: float64\n",
      "\n",
      "Best region for millennials (with cheapest avocados): Houston with an average price of  1.2707692307692307\n",
      "------------------------------------------\n",
      "4)\tIf you were an avocado seller and your income depended on selling highest amount of avocados which region would you take your avocado truck to based on the day. So which region would the truck go to on Monday, Wednesday and Friday? (30 points)\n",
      "\n",
      "The daily sales of avocados in each region: \n",
      "region\n",
      "Albany                 1.714445e+06\n",
      "Atlanta                5.636948e+05\n",
      "BaltimoreWashington    5.669063e+05\n",
      "Boise                  1.879109e+06\n",
      "Boston                 1.265017e+06\n",
      "BuffaloRochester       2.295430e+06\n",
      "California             3.598232e+06\n",
      "Charlotte              1.683738e+06\n",
      "Chicago                7.561991e+05\n",
      "CincinnatiDayton       6.501570e+05\n",
      "Columbus               1.901873e+06\n",
      "DallasFtWorth          5.013365e+05\n",
      "Denver                 8.163777e+05\n",
      "Detroit                1.152824e+06\n",
      "GrandRapids            1.313535e+06\n",
      "GreatLakes             2.311977e+06\n",
      "HarrisburgScranton     4.184794e+06\n",
      "HartfordSpringfield    4.722437e+06\n",
      "Houston                5.664197e+05\n",
      "Indianapolis           1.121858e+06\n",
      "Jacksonville           2.130106e+06\n",
      "LasVegas               3.608778e+06\n",
      "LosAngeles             1.912325e+06\n",
      "Louisville             9.492040e+05\n",
      "MiamiFtLauderdale      8.939561e+05\n",
      "Midsouth               2.404652e+06\n",
      "Nashville              2.375029e+06\n",
      "NewOrleansMobile       2.812084e+06\n",
      "NewYork                1.209583e+06\n",
      "Northeast              2.764406e+06\n",
      "NorthernNewEngland     3.242991e+06\n",
      "Orlando                2.980196e+06\n",
      "Philadelphia           5.703665e+06\n",
      "PhoenixTucson          2.903911e+05\n",
      "Pittsburgh             2.122001e+06\n",
      "Plains                 1.182268e+06\n",
      "Portland               1.370208e+06\n",
      "RaleighGreensboro      2.367802e+06\n",
      "RichmondNorfolk        4.271837e+06\n",
      "Roanoke                2.580995e+06\n",
      "Sacramento             3.509187e+06\n",
      "SanDiego               6.839022e+05\n",
      "SanFrancisco           4.030501e+05\n",
      "Seattle                3.092828e+06\n",
      "SouthCarolina          2.671106e+06\n",
      "SouthCentral           2.588352e+06\n",
      "Southeast              1.407844e+06\n",
      "Spokane                2.164641e+06\n",
      "StLouis                3.453851e+06\n",
      "Syracuse               1.252596e+06\n",
      "Tampa                  2.724059e+06\n",
      "West                   2.250739e+06\n",
      "WestTexNewMexico       3.515969e+05\n",
      "Name: Daily Volume, dtype: float64\n",
      "\n",
      "The best region to sell avocados on Monday, Wednesday, and Friday is Philadelphia with an daily volume of 5703664.994285714\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "data = pd.read_csv('../../data/raw/avocado/avocado.csv')\n",
    "\n",
    "# Get the basic info of the data\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Basic data cleaning and validation\n",
    "data = data[data['region'] != 'TotalUS']  # TotalUS is not a region\n",
    "data = data.drop([\"Unnamed: 0\", \"Date\"], axis=1)\n",
    "print(\"Check null data: \")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Outlier Detection and Removal\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Skewness Detection\n",
    "skewness_before = data[numeric_columns].skew()\n",
    "print(\"\\nSkewness of each numeric column before the removal of outliers: \")\n",
    "print(skewness_before)\n",
    "\n",
    "\n",
    "def outliers_count(df):\n",
    "    outlier_count_dict = {}\n",
    "\n",
    "    for column in df:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_thresh = q1 - (1.5 * iqr)\n",
    "        upper_thresh = q3 + (1.5 * iqr)\n",
    "\n",
    "        outlier_count = ((df[column] < lower_thresh) | (df[column] > upper_thresh)).sum()\n",
    "        outlier_count_dict[column] = outlier_count\n",
    "\n",
    "    return outlier_count_dict\n",
    "\n",
    "\n",
    "print(\"\\nNumber of outliers in each numeric column: \")\n",
    "outlier_counts = outliers_count(data[numeric_columns])\n",
    "\n",
    "df_before = pd.DataFrame(list(outlier_counts.items()), columns=[\"Column\", \"No. of outliers\"])\n",
    "df_before.reset_index(drop=True, inplace=True)\n",
    "print(df_before)\n",
    "\n",
    "\n",
    "def remove_outliers(df):\n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_thresh = q1 - (1.5 * iqr)\n",
    "    upper_thresh = q3 + (1.5 * iqr)\n",
    "    df_out = df[~((df < lower_thresh) | (df > upper_thresh)).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "data[numeric_columns] = remove_outliers(data[numeric_columns])\n",
    "\n",
    "skewness_after = data[numeric_columns].skew()\n",
    "print(\"\\nSkewness of each numeric column after the removal of outliers: \")\n",
    "print(skewness_after)\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Perform Yeo-Johnson Transformation to investigate the reduction of skewness\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "data2 = data.copy()\n",
    "data2[numeric_columns] = pt.fit_transform(data2[numeric_columns])\n",
    "\n",
    "skewness_after_transformation = data2[numeric_columns].skew()\n",
    "print(\"\\nSkewness of each numeric column after the Yeo-Johnson transformation: \")\n",
    "print(skewness_after_transformation)\n",
    "\n",
    "'''\n",
    "********\n",
    "Performing Yeo-Johnson Transformation can make the data more closely follow a normal distribution. However the \n",
    "transformation changes the values in the data so untransformed data would be used for analysis.\n",
    "********\n",
    "'''\n",
    "\n",
    "print(\n",
    "    \"\\nPerforming Yeo-Johnson Transformation can make the data more closely follow a normal distribution. However the \"\n",
    "    \"transformation changes the values in the data so untransformed data would be used for analysis.\")\n",
    "print(\"------------------------------------------\")\n",
    "# Analysis\n",
    "# Q1\n",
    "print(\"1)   Find out the average number of Avocados with PLU 4046 sold in each region (20 points)\")\n",
    "average_avocado_4046 = data.groupby('region')['4046'].mean()\n",
    "print(average_avocado_4046)\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Q2\n",
    "print(\"2)   Find out the top ten regions organized by total volume arranged highest to lowest (20 points)\")\n",
    "top_ten_regions_by_volume = data.groupby('region')['Total Volume'].sum().sort_values(ascending=False).head(10)\n",
    "print(top_ten_regions_by_volume)\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Q3\n",
    "print(\"3)   An average millennial has a rent of $2000. In general they spend 40% of their rent on food and 20% of \"\n",
    "      \"that amount is spent on breakfast. Which region is the best area to live for millennials if the millennial \"\n",
    "      \"like to have avocado toast breakfast every 1 time out of three (30 points) Assume you are having one avocado \"\n",
    "      \"in the breakfast.\")\n",
    "\n",
    "monthly_food_budget = 2000 * 0.4  # 800\n",
    "monthly_breakfast_budget = monthly_food_budget * 0.2  # 160\n",
    "avocado_budget_for_each = monthly_breakfast_budget / 30  # 5.33\n",
    "\n",
    "data['affordable'] = data['AveragePrice'] <= avocado_budget_for_each\n",
    "affordable_regions = data[data['affordable']]\n",
    "print(\"The average price of avocado with in each region:\")\n",
    "print(affordable_regions.groupby('region')['AveragePrice'].mean())\n",
    "best_region_for_millennials = affordable_regions.groupby('region')['AveragePrice'].mean().idxmin()\n",
    "print(\"\\nBest region for millennials (with cheapest avocados):\", best_region_for_millennials, \"with an average price \"\n",
    "                                                                                              \"of \",\n",
    "      min(affordable_regions.groupby('region')['AveragePrice'].mean()))\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Q4\n",
    "'''\n",
    "Assuming the sales data for each day of the week is evenly distributed throughout the week, the sales for each day \n",
    "would be estimated.\n",
    "'''\n",
    "print(\"4)\tIf you were an avocado seller and your income depended on selling highest amount of avocados which region \"\n",
    "      \"would you take your avocado truck to based on the day. So which region would the truck go to on Monday, \"\n",
    "      \"Wednesday and Friday? (30 points)\")\n",
    "\n",
    "# Calculate the daily sales assuming sales are evenly distributed throughout the week\n",
    "data['Daily Volume'] = data['Total Volume'] / 7\n",
    "\n",
    "# Estimate the sales for Monday, Wednesday, and Friday\n",
    "data['MWF Volume'] = data['Daily Volume'] * 3\n",
    "\n",
    "total_volume_mwf = data.groupby('region')['Daily Volume'].sum()\n",
    "\n",
    "print(\"\\nThe daily sales of avocados in each region: \")\n",
    "print(total_volume_mwf)\n",
    "best_region = total_volume_mwf.idxmax()\n",
    "print(\"\\nThe best region to sell avocados on Monday, Wednesday, and Friday is\", best_region,\n",
    "      \"with an daily volume of\",\n",
    "      max(data.groupby('region')['Daily Volume'].sum()))\n",
    "print(\"------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
